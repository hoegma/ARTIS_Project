\section{Methodology}
\label{sec:old-methods}

\subsection{Experimental Setup}

A fake face detection model is developed using federated learning (FL) to distinguish between real and fake faces.
First, a centrally trained model without FL is implemented and used as a baseline for performance comparison.
Second, a decentralized fake face detection model is trained using FL in a simulated multi-client environment.

\subsubsection{Dataset}

The well-known 140k real-fake faces dataset was used, which consists of 70,000 real faces and 70,000 fake faces with a image size of 256px~\cite{tunguz2020_140kreal_fake_faces}.
The fake faces were generated using StyleGAN, a generative adversarial network developed by NVIDIA that is capable of producing highly photorealistic synthetic facial images.

\subsubsection{Model}\label{subsubsec:model}

The base model chosen is EfficientNet-B0, a convolutional neural network (CNN), which was also used by Khudeyer et al.~\cite{khudeyer2023fake}.
The authors trained a fake face detection model using transfer learning.
For this purpose, the model was initialized with the pretrained weights of EfficientNetB0 on the ImageNet dataset.
A lightweight head was attached to the pre-trained base model, consisting of global average pooling, a 256-dimensional fully connected layer with ReLU activation, batch normalization, and dropout, followed by a 2 dimensional softmax output layer.
The output is a 2-dimensional vector with probabilities indicating whether the input image is a fake or real face.
The model was optimized with binary cross-entropy loss and the Adam optimizer.
All input images for training were resized to 244px.

\subsection{Centralized Fake Face Detection Model}

The authors of~\cite{khudeyer2023fake} developed a method for fake face detection using CNN, which achieves an accuracy of 99.06\%.
This approach is used as a benchmark for comparing central fake face detection with fake face detection using FL.
This work was reimplemented for verification purposes in order to ensure a meaningful comparison.
\newline
The dataset was divided into 100.000 training images, 20.000 test images, and 20.000 validation images.
EfficientNetB0 with the hyperparameters of section~\ref{subsubsec:model} is used.
Training was performed with a batch size of 32 over 30 epochs with early stopping to reduce training time.
\newline
The paper presented a learning rate scheduler that adjusts the learning rate during training based on the epoch, as shown in Table~\ref{tab:learning_rate_scheduler}.
\begin{table}[t]
    \centering
    \begin{tabular}{l c}
    \hline
    \textbf{Epoch} & \textbf{Learning rate} \\
    \hline
    $epoch \leq 2$ & 0.01 \\
    $2 < epoch \leq 15$ & 0.001 \\
    $epoch > 15$ & 0.0001 \\
    \hline
    \end{tabular}
    \caption{Adjustment of the learning rate during training.}
    \label{tab:learning_rate_scheduler}
\end{table}
The learning rate scheduler ensures that significant weight adjustments are made early in training.
Furthermore, in later iterations, a strong adjustment is prevented by the decreasing learning rate.
This leads to faster convergence in early epochs, while weight optimizations can be performed in later itterations.
\newline
Due to time constraints, the model was only trained once, as training was very computationally intensive due to the large amount of data.

% \subsection{Decentralized Fake Face Detection using FL}

% In this section a decentralized trained fake face detection model is developed.
% The training process will be explained below.
% In addition, we will discuss how privacy attacks can be prevented during training.

% \subsubsection{Research Scenario}

% The following scenario is fictional.
% \newline
% Several research organizations want to work together to train a fake face detection model.
% Each individual organization has images of fake faces, but also images of faces that belong to their customers.
% An ML model should be trained together that can distinguish between real and fake images.
% To do this, a large data set containing all images would have to be created in order to train the model.
% However, all organizations are interested in protecting the privacy of their customers and therefore do not want to share the real images.
% The solution is to train the model using FL.
% This fake face detection model should be trained with all data from all organizations and should be available to everyone
% without the need to share data between organizations.

% \subsubsection{Thread Model}

% All participants in the fake face detection training process are trusted.
% This means that all model performance attacks that seek to undermine the convergence of the global model can be excluded.
% After training, participants send their model weights to a trusted third-party server.
% This ensures the secure aggregation of weights.
% Weights sent by participants to the trusted third party could be captured during transmission.
% Capturing the weights of individual organizations represents an attack vector for privacy attacks.
% This attack vector should be reduced by the proposed encryption.

% \subsubsection{FL Simulation}

% A simulation environment is developed to simulate a global model with any number of participants.
% The EfficientNetB0 with the hyperparameters of section~\ref{subsubsec:model} is used as the base model.
% A batch size of 128 is selected.
% The training data set was divided among five participants, with each receiving approximately 20,000 images, comprising 10,000 real faces and 10,000 fake faces.
% On the server, the global model is initialized with the weights from EfficientNetB0, which was pre-trained on the ImageNet dataset.
% The global model is trained in 10 epochs.
% \newline
% Each epoch consists of the following steps.
% \newline
% First, the weights of the global model are distributed among the 5 participants.
% Each participant initializes their local model with the global weights.
% The participants train their local models in 3 epochs.
% The weights of the local models are encrypted to prevent privacy attacks by intercepting the weights.
% The server receives the weights and decrypts them.
% The global model parameters are updated using weighted federated averaging (FedAvg), where each client's contribution is proportional to the number of local samples.

% \subsubsection{FL attack mitigations}

% If the local updates of the participants are captured during transmission to the server, privacy attacks on the participants' data can be carried out.
% To counteract this, the weight updates must be encrypted.
% The weights are serialized in bytes and encrypted with AES-128.
% Each participant has a secret key that the server knows as a trusted third party.
% When a server receives the encrypted data, it can decrypt it for further processing.

\subsection{Decentralized Fake Face Detection Development}

The transition from a centralized to a decentralized model was conducted in two phases: an initial implementation using an automated framework, followed by a custom-built manual Federated Learning (FL) system to accommodate specific security requirements.

\subsubsection{Phase 1: Automated FL via Flower Framework}
Initially, the decentralized model was implemented using the \textit{Flower} framework. This phase served to validate the feasibility of training EfficientNet-B0 in a multi-client environment. However, during development, significant technical challenges arose regarding the integration of custom encryption layers within the Flower abstraction. This limitation necessitated the development of a more transparent, manual FL pipeline.

\subsubsection{Phase 2: Manual FL with Weight Encryption}
To ensure full control over the aggregation process and security protocols, a manual FL simulation was developed. The environment simulates a global server and five distinct participants (clients). Each client is allocated a shard of the dataset (approximately 20,000 images) using $tf.data.shard$ to maintain memory efficiency.

\paragraph{Training Loop:} 
The global model is initialized with ImageNet weights. In each of the 10 federated rounds:
\begin{enumerate}
    \item The server broadcasts the current global weights to all active clients.
    \item Each client performs 3 local epochs of training using a categorical cross-entropy loss and the Adam optimizer.
    \item Clients serialize their local weight updates into byte streams.
    \item These updates are encrypted using AES-128 via the Fernet symmetric encryption library before being transmitted back to the server.
\end{enumerate}

\paragraph{Secure Aggregation:}
We initially explored \textbf{Secure Aggregation} protocols using ready-made frameworks (TensorFlow Federated SecAgg, Flower SecAgg) but faced integration challenges with our custom TensorFlow/Keras pipeline. We ultimately selected \textbf{Fernet} symmetric encryption for seamless compatibility.

Clients encrypt model weights via \texttt{Fernet.encrypt()} before transmission; the server decrypts with the shared key prior to aggregation.

Upon receiving the encrypted updates, the server performs decryption and updates the global model using a \textit{Weighted Federated Averaging} (FedAvg) algorithm. The contribution of client $k$ is weighted by its sample size $n_k$ relative to the total samples $N$:
\[ W_{global} = \sum_{k=1}^{K} \frac{n_k}{N} W_k \]
This ensures that the global model converges effectively while preserving the privacy of the local data through the encryption of model parameters during transit.

\subsubsection{Threat Model and Privacy}
The primary attack vector addressed in this architecture is the interception of model weights during transmission. By implementing Fernet-based encryption, we ensure that even if a third party captures the packets between the client and the server, the underlying gradients—which could potentially be used for reconstruction attacks—remain inaccessible without the shared secret key.

\subsection{Fernet Encryption for Secure Weight Transmission}

To ensure privacy-preserving communication, this implementation employs \textbf{Fernet symmetric encryption} from Python's \texttt{cryptography} library. Model weights are encrypted on clients before transmission to the central server, preventing eavesdropping and ensuring data integrity via AES-128-CBC encryption combined with HMAC-SHA256 authentication.

\subsubsection{Encryption Workflow}
The secure aggregation pipeline operates as follows:

\begin{enumerate}
    \item \textbf{Client Training}: Local model produces updated weights $\mathbf{W}_i$ after $E=3$ epochs
    \item \textbf{Serialization}: $\mathbf{W}_i \rightarrow$ \texttt{pickle.dumps()} $\rightarrow$ raw bytes
    \item \textbf{Encryption}: Bytes $\rightarrow$ \texttt{cipher.encrypt()} $\rightarrow$ Fernet token $T_i$
    \item \textbf{Transmission}: Client sends compact $T_i$ (33\% overhead) over untrusted channel
    \item \textbf{Server Decryption}: $T_i \rightarrow$ \texttt{cipher.decrypt()} $\rightarrow$ verified $\mathbf{W}_i$
    \item \textbf{Weighted FedAvg}: $\mathbf{W}_{global} = \sum_i \frac{n_i}{N} \mathbf{W}_i$ where $n_i$ = client samples
\end{enumerate}

Fernet tokens self-contain timestamp, IV, ciphertext, and HMAC, providing confidentiality, authenticity, and replay protection. A single 32-byte key (16B AES + 16B HMAC) is shared securely for the simulation.



\subsection{Explainability using SHAP}

In order to analyze the centrally trained model and the decentralized trained model, the decisions made by the models should be compared for individual inputs.
The aim is to clarify whether the models have developed differently as a result of the different training processes and whether they focus on different details when making decisions.
The SHAP method is used for this purpose.





